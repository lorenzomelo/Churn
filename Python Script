import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


data = pd.read_csv("churn.csv")
data = data.drop(data.columns[0:2], axis = 1)

data.info()
data.head()
data.isna().sum()

data.columns


df_pie = data.groupby("Attrition_Flag").size().to_frame(' ')
plt.pie([1627, 8500], labels = ['Attrited Customer', 'Existing Customer'], colors = sns.color_palette('hls'), autopct='%.0f%%')

df_plt = data[data['Attrition_Flag'].isin(['Attrited Customer', 'Existing Customer']) ]
ax = sns.countplot(data = df_plt, x = "Attrition_Flag", hue="Attrition_Flag", palette="Set2")
n_records = float(len(data))
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2., height + 1, '{:1.2%}'.format(height/n_records), ha="center", fontsize =7)
 
data["Total_Relationship_Count"].value_counts()
df_plt3 = data[data['Total_Relationship_Count'].isin([1,2,3,4,5,6])]
sns.countplot(data = df_plt3, x = "Total_Relationship_Count", hue="Attrition_Flag", palette="Set2")  

data["Contacts_Count_12_mon"].value_counts()
df_plt4 = data[data['Contacts_Count_12_mon'].isin([0,1,2,3,4,5,6])]
sns.countplot(data = df_plt4, x = "Contacts_Count_12_mon", hue="Attrition_Flag", palette="Set2")  

data["Card_Category"].value_counts()
df_plt5 = data[data['Card_Category'].isin(["Blue", "Silver", "Gold", "Platinum"])]
sns.countplot(data = df_plt4, x = "Card_Category", hue="Attrition_Flag", palette="Set2")  

sns.histplot(data = data, x = "Total_Trans_Amt", hue = 'Attrition_Flag', multiple="stack", palette="Set2", kde=True) 
ax = sns.boxplot(x = data['Total_Trans_Amt'])

sns.histplot(data = data, x = "Avg_Utilization_Ratio", hue = 'Attrition_Flag', multiple="stack", palette="Set2", kde=True) 
ax2 = sns.boxplot(x = data['Avg_Utilization_Ratio'])

sns.histplot(data = data, x = "Credit_Limit", hue = 'Attrition_Flag', multiple="stack", palette="Set2", kde=True) 
ax4 = sns.boxplot(x = data['Credit_Limit'])

ax5 = sns.boxplot(x = data['Months_on_book'])
ax6 = sns.boxplot(x = data['Total_Relationship_Count'])
ax7 = sns.boxplot(x = data['Months_Inactive_12_mon'])
ax8 = sns.boxplot(x = data['Contacts_Count_12_mon'])
ax9 = sns.boxplot(x = data['Total_Trans_Ct'])

corr = data.corr()
ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)
ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')


#UNDERSAMPLING
import random
class_2,class_1 = data.Attrition_Flag.value_counts()
c2 = data[data['Attrition_Flag'] == 0]
c1 = data[data['Attrition_Flag'] == 1]
random.seed(42)
df_2 = c2.sample(class_1)
under_data = pd.concat([df_2,c1],axis=0)
under_data.Attrition_Flag.value_counts()

from numpy.random import default_rng
rng = default_rng(2022) # Set seed
train = rng.choice(int(under_data.shape[0]), size=int(round(under_data.shape[0]*0.8)), replace=False)
test = [i for i in range(under_data.shape[0]) if i not in train]
train_y, train_X = under_data.iloc[train, 0].values, under_data.iloc[train, 1:].values
test_y, test_X = under_data.iloc[test, 0].values, under_data.iloc[test, 1:].values
print(train_y.shape, train_X.shape, test_y.shape, test_X.shape)



### SVC ####
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
train_X = sc.fit_transform(train_X)
test_X = sc.transform(test_X)

# tuning
#modelsvc = SVC()
#param = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),'C' : [1,5,10],'degree' : [3,8],'coef0' : [0.01,10,0.5],'gamma' : ('auto','scale')}
#CV_svc= GridSearchCV(estimator=modelsvc, param_grid=param, cv=5)
#CV_svc.fit(train_X, train_y)
#print(CV_svc.best_params_)

# model
svc_model = SVC(C=1, coef0=0.5, degree=3, gamma='scale', kernel='poly')
svc_model.fit(train_X, train_y)
y_pred_svc = svc_model.predict(test_X)

from sklearn.metrics import accuracy_score, precision_score, recall_score
accuracy_train = svc_model.score(train_X, train_y)
print("SVC - Accuracy on the training set: " + str(accuracy_train))
print("SVC - Accuracy on the test set: " + str(accuracy_score(test_y, y_pred_svc)))
print("SVC - Precision: " + str(precision_score(test_y, y_pred_svc)))
print("SVC - Recall: " + str(recall_score(test_y, y_pred_svc)))



### RANDOM FOREST ###
from sklearn.ensemble import RandomForestClassifier

# tuning
#rf_final = RandomForestClassifier(random_state=0)
#param_grid = {
#    'n_estimators': [100, 500],
#    'max_features': ['auto', 'sqrt', 'log2'],
#    'max_depth': [4, 5, 6, 7, 8],
#    'criterion': ['gini', 'entropy']
#}
#CV_rfc = GridSearchCV(estimator=rf_final, param_grid=param_grid, cv=5)
#CV_rfc.fit(train_X, train_y)
#print(CV_rfc.best_params_)

#model
rfc1=RandomForestClassifier(random_state=0, max_features='auto', n_estimators= 500, max_depth=8, criterion='entropy')
rfc1.fit(train_X, train_y)
y_pred = rfc1.predict(test_X)

#ACCURACY
accuracy_train = rfc1.score(train_X, train_y)
print("Random Forest - Accuracy on the training set: " + str(accuracy_train))
print("Random Forest - Accuracy on the test set: " + str(accuracy_score(test_y, y_pred)))
print("Random Forest - Precision: " + str(precision_score(test_y, y_pred)))
print("Random Forest - Recall: " + str(recall_score(test_y, y_pred)))



### LOGISTIC REGRESSION ###
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(train_X, train_y.ravel())
y_pred_log = logreg.predict(test_X)
y_pred_log = pd.DataFrame(y_pred_log)

accuracy_train = logreg.score(train_X, train_y)
print("Accuracy on the training set: " + str(accuracy_train))
print("Logistic Regression - Accuracy on the test set: " + str(accuracy_score(test_y, y_pred_log)))
print("Logistic Regression - Precision: " + str(precision_score(test_y, y_pred_log)))
print("Logistic Regression - Recall: " + str(recall_score(test_y, y_pred_log)))

